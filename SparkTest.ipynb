{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Code required to get Spark environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.output_text { font-size: 14px; }.CodeMirror { font-size: 14px; }.container { width: 90% !important; font-size: 14px; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## This is a helper script I have been running for a long time to provide as much width as needed (and is practical)\n",
    "## Also provides simple mods for cell/output text size and several other hacks\n",
    "%run display.py\n",
    "get_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import UserDict\n",
    "# import types as types_from_types\n",
    "# import pyspark.sql.functions as F\n",
    "# from pyspark.sql import DataFrame, Row\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.context import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_conf = {\n",
    "    \"spark.plugins\": \"org.apache.spark.sql.connect.SparkConnectPlugin\"\n",
    "}\n",
    "overwrite_conf = {\n",
    "    \"spark.master\": \"master\",\n",
    "}\n",
    "def create_conf(**kwargs: Any) -> SparkConf:\n",
    "    sparkConf = SparkConf(**kwargs)\n",
    "    for k, v in overwrite_conf.items():\n",
    "        sparkConf.set(k, v)\n",
    "    for k, v in default_conf.items():\n",
    "        if not sparkConf.contains(k):\n",
    "            sparkConf.set(k, v)\n",
    "    return sparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fun for another time...\n",
    "\n",
    "local_conf = {\n",
    "    \"spark.cores.max\": 6,\n",
    "    \"spark.driver.cores\": 2,\n",
    "    \"spark.driver.memory\": \"4g\",\n",
    "    \"spark.executor.memory\": \"3g\",\n",
    "    \"spark.executor.cores\": 3,\n",
    "    \"spark.logConf\": True,\n",
    "    \"spark.shuffle.service.enabled\": True,\n",
    "    \"spark.dynamicAllocation.enabled\": True,\n",
    "    \"spark.dynamicAllocation.minExecutors\": 4,\n",
    "    \"spark.dynamicAllocation.maxExecutors\": 6,\n",
    "    \"spark.default.parallelism\": 16\n",
    "}\n",
    "\n",
    "conf = SparkConf(local_conf)\n",
    "conf.setMaster(\"local[*]\").setAppName(\"DataEngineeringTest\")\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_doc_num                 = \"DocumentNumber\"\n",
    "col_doc_dt                  = \"DocumentDate\"\n",
    "col_doc_type                = \"DocumentType\"\n",
    "col_ref_to_doc_num          = \"RefersToDocumentNumber\"\n",
    "col_ref_to_doc_year         = \"RefersToDocumentYear\"\n",
    "col_remarks                 = \"Remarks\"\n",
    "\n",
    "col_formatted_doc_dt        = \"FormattedDocumentDate\"\n",
    "\n",
    "col_ref_year_ref_num_arr    = \"RefYearRefNumArray\"\n",
    "col_ref_year_num_concat     = \"RefYearNumConcat\"\n",
    "\n",
    "col_year_num_arr            = \"YearNumArray\"\n",
    "col_year_num_concat         = \"YearNumConcat\"\n",
    "\n",
    "col_all                     = col('*')\n",
    "\n",
    "key_types_jrt               = ('J','T','R')\n",
    "key_types_abc               = ('A','B','C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_df(df, n=25, orderby_cols=(col_doc_type, col_ref_to_doc_num)):\n",
    "    df.orderBy(*orderby_cols).show(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('data-engineer-interview-data.csv', header=True, inferSchema=True, samplingRatio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \"Make\" the date from scratch using the existing repr, need to be careful of M/d/yyy vs. MM/dd/yyyy (e.g.)\n",
    "df = df.select(\"*\", split(col_doc_dt, \"/\").alias('dt')).withColumn(col_formatted_doc_dt,\n",
    "        to_date(make_date(month=col(\"dt\").__getitem__(0), day=col(\"dt\").__getitem__(1), year=col(\"dt\").__getitem__(2)), 'MM/dd/yyyy'))\n",
    "df = df.orderBy(col_doc_type, col_doc_num).drop('dt').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since the two \"Reference\" cols had years and nums in both, I created this func() to ensure the year was first in the concatenation of \"year.num\" being handy later for\n",
    "## the joins. I explored the data quite a bit and saw that the only length 4 entries between the two \"Reference\" cols were also within the min/max range of years that \n",
    "## substiantiated the \"DocumentDate\" field so, for this assignment I made the assumption that they had been entered in the opposing fields occasionally, as mentioned\n",
    "def concat_cols(df, first_col, second_col, final_col_name):\n",
    "    concat_ref_col = when(length(first_col) == 4,\n",
    "                        concat_ws('.', first_col, second_col)).otherwise(\n",
    "                            concat_ws('.', second_col, first_col))\n",
    "    return df.withColumn(final_col_name, concat_ref_col)\n",
    "\n",
    "df = concat_cols(df, col(col_ref_to_doc_num), col(col_ref_to_doc_year), col_ref_year_num_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = concat_cols(df, year(col_formatted_doc_dt), col(col_doc_num), col_year_num_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DocumentNumber', 'DocumentDate', 'DocumentType', 'RefersToDocumentNumber', 'RefersToDocumentYear', 'Remarks', 'FormattedDocumentDate', 'RefYearNumConcat', 'YearNumConcat']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_keys = {row[0]: row[1] for row in df.groupBy(col(col_doc_type)).count().collect()}.keys()\n",
    "others = sorted([t for t in type_keys if t not in key_types_jrt])\n",
    "\n",
    "col_with_temp = lambda c: (c, f\"{c}_TEMP\")\n",
    "only_temp_col = lambda c: col_with_temp(c)[-1]\n",
    "temp_for_col = lambda c: (f\"{c}_TEMP\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doctype_with_temp_col(df, doc_type_chars, cur_col_to_temp):\n",
    "    return df.where(col(col_doc_type).isin(doc_type_chars)).withColumnRenamed(*col_with_temp(cur_col_to_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 9, 28, 89)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split off DataFrames per needs outlined in the docs, using helpers to make subsequent joins easier\n",
    "dfj = get_doctype_with_temp_col(df, 'J', col_year_num_concat)\n",
    "dft= get_doctype_with_temp_col(df, 'T', col_ref_year_num_concat)\n",
    "dfabc = get_doctype_with_temp_col(df, others, col_year_num_concat)\n",
    "dfr = get_doctype_with_temp_col(df, 'R', col_ref_year_num_concat)\n",
    "dfj.count(), dft.count(), dfr.count(), dfabc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfj count before anti_join: [20], dfj_applied count after: [13]\n"
     ]
    }
   ],
   "source": [
    "## Used anti joins, which is ideal for discounting rows from a larger spread, but it works fine this way also with union reconstruction later\n",
    "dfj_applied = dfj.join(dft, on=[dfj[only_temp_col(col_year_num_concat)] == dft[only_temp_col(col_ref_year_num_concat)]], how=\"left_anti\")\n",
    "print(f\"dfj count before anti_join: [{dfj.count()}], dfj_applied count after: [{dfj_applied.count()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+------------+----------------------+--------------------+-------+---------------------+----------------+------------------+\n",
      "|DocumentNumber|DocumentDate|DocumentType|RefersToDocumentNumber|RefersToDocumentYear|Remarks|FormattedDocumentDate|RefYearNumConcat|YearNumConcat_TEMP|\n",
      "+--------------+------------+------------+----------------------+--------------------+-------+---------------------+----------------+------------------+\n",
      "|            37|   7/24/1987|           J|                  null|                null|       |           1987-07-24|                |           1987.37|\n",
      "|            52|  12/22/2006|           J|                  null|                null|       |           2006-12-22|                |           2006.52|\n",
      "|            73|  11/13/2003|           J|                  null|                null|       |           2003-11-13|                |           2003.73|\n",
      "|           125|  12/16/1993|           J|                  null|                null|       |           1993-12-16|                |          1993.125|\n",
      "|           133|  11/16/1995|           J|                  null|                null|       |           1995-11-16|                |          1995.133|\n",
      "|           137|    7/2/1997|           J|                  null|                null|       |           1997-07-02|                |          1997.137|\n",
      "|           144|    5/9/2013|           J|                  null|                null|       |           2013-05-09|                |          2013.144|\n",
      "+--------------+------------+------------+----------------------+--------------------+-------+---------------------+----------------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## These are the records that matched but due to\n",
    "## the join type were not included in the result\n",
    "## And there are indeed a total of [7] records\n",
    "dfj.subtract(dfj_applied).orderBy(col_doc_num).show(7)\n",
    "dfj.subtract(dfj_applied).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfabc count before anti_join: [89], dfabc_applied count after: [63]\n"
     ]
    }
   ],
   "source": [
    "dfabc_applied = dfabc.join(dfr, on=[dfabc[col_with_temp(col_year_num_concat)[-1]] == dfr[col_with_temp(col_ref_year_num_concat)[-1]]], how=\"left_anti\")\n",
    "print(f\"dfabc count before anti_join: [{dfabc.count()}], dfabc_applied count after: [{dfabc_applied.count()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+------------+----------------------+--------------------+-----------+---------------------+----------------+------------------+\n",
      "|DocumentNumber|DocumentDate|DocumentType|RefersToDocumentNumber|RefersToDocumentYear|    Remarks|FormattedDocumentDate|RefYearNumConcat|YearNumConcat_TEMP|\n",
      "+--------------+------------+------------+----------------------+--------------------+-----------+---------------------+----------------+------------------+\n",
      "|             1|   10/2/2000|           A|                  null|                null|$10,000.00 |           2000-10-02|                |            2000.1|\n",
      "|             9|  12/19/1988|           A|                  null|                null|           |           1988-12-19|                |            1988.9|\n",
      "|            28|  10/14/1994|           A|                  null|                null|           |           1994-10-14|                |           1994.28|\n",
      "|            55|   5/19/1989|           A|                  null|                null|           |           1989-05-19|                |           1989.55|\n",
      "|            65|    7/2/1997|           A|                  null|                null|           |           1997-07-02|                |           1997.65|\n",
      "|            78|    2/8/1991|           A|                  null|                null|           |           1991-02-08|                |           1991.78|\n",
      "|            86|    1/2/1997|           A|                  null|                null|           |           1997-01-02|                |           1997.86|\n",
      "|            94|   8/21/1992|           A|                  null|                null|           |           1992-08-21|                |           1992.94|\n",
      "|            97|   2/18/1992|           A|                  null|                null|           |           1992-02-18|                |           1992.97|\n",
      "|            98|  10/17/2016|           A|                  null|                null|           |           2016-10-17|                |           2016.98|\n",
      "|           113|   4/16/1991|           A|                  1989|                  55|           |           1991-04-16|         1989.55|          1991.113|\n",
      "|           130|  11/27/2015|           A|                  2013|                  84|           |           2015-11-27|         2013.84|          2015.130|\n",
      "|           163|   8/28/1987|           A|                  null|                null|           |           1987-08-28|                |          1987.163|\n",
      "|            15|    9/7/2001|           B|                  null|                null|           |           2001-09-07|                |           2001.15|\n",
      "|            69|   7/24/1987|           B|                  null|                null|           |           1987-07-24|                |           1987.69|\n",
      "|            84|   9/23/2013|           B|                  null|                null|           |           2013-09-23|                |           2013.84|\n",
      "|            88|   8/28/1987|           B|                  null|                null|           |           1987-08-28|                |           1987.88|\n",
      "|           100|  12/24/2010|           B|                  null|                null|           |           2010-12-24|                |          2010.100|\n",
      "|           168|    2/1/1993|           B|                  null|                null|           |           1993-02-01|                |          1993.168|\n",
      "|           199|  11/29/2002|           B|                  2001|                  15|           |           2002-11-29|         2001.15|          2002.199|\n",
      "|            21|    2/8/1991|           C|                  null|                null|           |           1991-02-08|                |           1991.21|\n",
      "|            23|    9/8/1999|           C|                  null|                null|           |           1999-09-08|                |           1999.23|\n",
      "|            78|   4/16/1991|           C|                  null|                null|           |           1991-04-16|                |           1991.78|\n",
      "|           100|    2/5/2010|           C|                  null|                null|           |           2010-02-05|                |          2010.100|\n",
      "|           132|   4/16/1991|           C|                  null|                null|           |           1991-04-16|                |          1991.132|\n",
      "|           227|   8/28/1987|           C|                  null|                null|           |           1987-08-28|                |          1987.227|\n",
      "+--------------+------------+------------+----------------------+--------------------+-----------+---------------------+----------------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## These are the records that matched but due to\n",
    "## the join type were not included in the result\n",
    "## And there are indeed a total of [26] records\n",
    "dfabc.subtract(dfabc_applied).orderBy(col_doc_type, col_doc_num).show(26)\n",
    "dfabc.subtract(dfabc_applied).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Could have done this with a comprehension but the result is still a Potato\n",
    "df_final = (dfj_applied.withColumnRenamed(*temp_for_col(col_year_num_concat)).union(\n",
    "    dfabc_applied.withColumnRenamed(*temp_for_col(col_year_num_concat)).union(\n",
    "        dfr.withColumnRenamed(*temp_for_col(col_ref_year_num_concat)).union(\n",
    "            dft.withColumnRenamed(*temp_for_col(col_ref_year_num_concat))\n",
    "        ))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+------------+----------------------+--------------------+-----------+---------------------+----------------+-------------+\n",
      "|DocumentNumber|DocumentDate|DocumentType|RefersToDocumentNumber|RefersToDocumentYear|    Remarks|FormattedDocumentDate|RefYearNumConcat|YearNumConcat|\n",
      "+--------------+------------+------------+----------------------+--------------------+-----------+---------------------+----------------+-------------+\n",
      "|             1|   10/2/2000|           A|                  null|                null|$10,000.00 |           2000-10-02|                |       2000.1|\n",
      "|             9|  12/19/1988|           A|                  null|                null|           |           1988-12-19|                |       1988.9|\n",
      "|            28|  10/14/1994|           A|                  null|                null|           |           1994-10-14|                |      1994.28|\n",
      "|            55|   5/19/1989|           A|                  null|                null|           |           1989-05-19|                |      1989.55|\n",
      "|            65|    7/2/1997|           A|                  null|                null|           |           1997-07-02|                |      1997.65|\n",
      "|            78|    2/8/1991|           A|                  null|                null|           |           1991-02-08|                |      1991.78|\n",
      "|            86|    1/2/1997|           A|                  null|                null|           |           1997-01-02|                |      1997.86|\n",
      "|            94|   8/21/1992|           A|                  null|                null|           |           1992-08-21|                |      1992.94|\n",
      "|            97|   2/18/1992|           A|                  null|                null|           |           1992-02-18|                |      1992.97|\n",
      "|            98|  10/17/2016|           A|                  null|                null|           |           2016-10-17|                |      2016.98|\n",
      "|           113|   4/16/1991|           A|                  1989|                  55|           |           1991-04-16|         1989.55|     1991.113|\n",
      "|           130|  11/27/2015|           A|                  2013|                  84|           |           2015-11-27|         2013.84|     2015.130|\n",
      "|           163|   8/28/1987|           A|                  null|                null|           |           1987-08-28|                |     1987.163|\n",
      "|            15|    9/7/2001|           B|                  null|                null|           |           2001-09-07|                |      2001.15|\n",
      "|            69|   7/24/1987|           B|                  null|                null|           |           1987-07-24|                |      1987.69|\n",
      "|            84|   9/23/2013|           B|                  null|                null|           |           2013-09-23|                |      2013.84|\n",
      "|            88|   8/28/1987|           B|                  null|                null|           |           1987-08-28|                |      1987.88|\n",
      "|           100|  12/24/2010|           B|                  null|                null|           |           2010-12-24|                |     2010.100|\n",
      "|           168|    2/1/1993|           B|                  null|                null|           |           1993-02-01|                |     1993.168|\n",
      "|           199|  11/29/2002|           B|                  2001|                  15|           |           2002-11-29|         2001.15|     2002.199|\n",
      "|            21|    2/8/1991|           C|                  null|                null|           |           1991-02-08|                |      1991.21|\n",
      "|            23|    9/8/1999|           C|                  null|                null|           |           1999-09-08|                |      1999.23|\n",
      "|            78|   4/16/1991|           C|                  null|                null|           |           1991-04-16|                |      1991.78|\n",
      "|           100|    2/5/2010|           C|                  null|                null|           |           2010-02-05|                |     2010.100|\n",
      "|           132|   4/16/1991|           C|                  null|                null|           |           1991-04-16|                |     1991.132|\n",
      "|           227|   8/28/1987|           C|                  null|                null|           |           1987-08-28|                |     1987.227|\n",
      "|            37|   7/24/1987|           J|                  null|                null|           |           1987-07-24|                |      1987.37|\n",
      "|            52|  12/22/2006|           J|                  null|                null|           |           2006-12-22|                |      2006.52|\n",
      "|            73|  11/13/2003|           J|                  null|                null|           |           2003-11-13|                |      2003.73|\n",
      "|           125|  12/16/1993|           J|                  null|                null|           |           1993-12-16|                |     1993.125|\n",
      "|           133|  11/16/1995|           J|                  null|                null|           |           1995-11-16|                |     1995.133|\n",
      "|           137|    7/2/1997|           J|                  null|                null|           |           1997-07-02|                |     1997.137|\n",
      "|           144|    5/9/2013|           J|                  null|                null|           |           2013-05-09|                |     2013.144|\n",
      "+--------------+------------+------------+----------------------+--------------------+-----------+---------------------+----------------+-------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(113, 146)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.subtract(df_final).orderBy(col_doc_type, col_doc_num).show(26 + 7)\n",
    "df_final.count(), df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## More of a traditional audit trail can be integrated via py4j to really get after the action \n",
    "## happening in each jvm and to record each individual record that is or isn't included in the\n",
    "## final result set. It seems kind of silly to set that up just for this. But, in production,\n",
    "## we can get as granular as we want. We can debug and log/audit at the task level when needed\n",
    "## For now, you can clearly see the differences in the joins add up to that of the final counts"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
